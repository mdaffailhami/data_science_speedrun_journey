{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import polars as pl\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1_000, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>review</th><th>overall</th><th>sentiment</th></tr><tr><td>str</td><td>f64</td><td>str</td></tr></thead><tbody><tr><td>&quot;Da Silva takes the divine by s…</td><td>4.0</td><td>&quot;POSITIVE&quot;</td></tr><tr><td>&quot;For me personally it&#x27;s the mos…</td><td>2.0</td><td>&quot;NEGATIVE&quot;</td></tr><tr><td>&quot;Very simple book, but leaves y…</td><td>4.0</td><td>&quot;POSITIVE&quot;</td></tr><tr><td>&quot;I read a library copy of this …</td><td>5.0</td><td>&quot;POSITIVE&quot;</td></tr><tr><td>&quot;With the government knowing th…</td><td>5.0</td><td>&quot;POSITIVE&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;I thoroughly enjoyed this book…</td><td>5.0</td><td>&quot;POSITIVE&quot;</td></tr><tr><td>&quot;I was impressed with not only …</td><td>5.0</td><td>&quot;POSITIVE&quot;</td></tr><tr><td>&quot;I like the characters.  I had …</td><td>5.0</td><td>&quot;POSITIVE&quot;</td></tr><tr><td>&quot;She got way she wanted,but can…</td><td>5.0</td><td>&quot;POSITIVE&quot;</td></tr><tr><td>&quot;All these twists, turns and di…</td><td>5.0</td><td>&quot;POSITIVE&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1_000, 3)\n",
       "┌─────────────────────────────────┬─────────┬───────────┐\n",
       "│ review                          ┆ overall ┆ sentiment │\n",
       "│ ---                             ┆ ---     ┆ ---       │\n",
       "│ str                             ┆ f64     ┆ str       │\n",
       "╞═════════════════════════════════╪═════════╪═══════════╡\n",
       "│ Da Silva takes the divine by s… ┆ 4.0     ┆ POSITIVE  │\n",
       "│ For me personally it's the mos… ┆ 2.0     ┆ NEGATIVE  │\n",
       "│ Very simple book, but leaves y… ┆ 4.0     ┆ POSITIVE  │\n",
       "│ I read a library copy of this … ┆ 5.0     ┆ POSITIVE  │\n",
       "│ With the government knowing th… ┆ 5.0     ┆ POSITIVE  │\n",
       "│ …                               ┆ …       ┆ …         │\n",
       "│ I thoroughly enjoyed this book… ┆ 5.0     ┆ POSITIVE  │\n",
       "│ I was impressed with not only … ┆ 5.0     ┆ POSITIVE  │\n",
       "│ I like the characters.  I had … ┆ 5.0     ┆ POSITIVE  │\n",
       "│ She got way she wanted,but can… ┆ 5.0     ┆ POSITIVE  │\n",
       "│ All these twists, turns and di… ┆ 5.0     ┆ POSITIVE  │\n",
       "└─────────────────────────────────┴─────────┴───────────┘"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = []\n",
    "overalls = []\n",
    "sentiments = []\n",
    "\n",
    "with open('./data/Books_small.json') as file:\n",
    "    for line in file:\n",
    "        row = json.loads(line)\n",
    "\n",
    "        reviews.append(row['reviewText'])\n",
    "        overalls.append(row['overall'])\n",
    "\n",
    "        if row['overall'] <= 2:\n",
    "            sentiments.append('NEGATIVE')\n",
    "        elif row['overall'] == 3:\n",
    "            sentiments.append('NEUTRAL')\n",
    "        else:\n",
    "            sentiments.append('POSITIVE')\n",
    "\n",
    "df = pl.DataFrame({\n",
    "    'review': reviews,\n",
    "    'overall': overalls,\n",
    "    'sentiment': sentiments\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750, 3) (250, 3)\n"
     ]
    }
   ],
   "source": [
    "training_df, test_df = train_test_split(df, test_size=0.25)\n",
    "print(training_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750, 2) (750,)\n",
      "(250, 2) (250,)\n"
     ]
    }
   ],
   "source": [
    "training_x_df = training_df[['review', 'overall']]\n",
    "training_y_df = training_df['sentiment']\n",
    "\n",
    "test_x_df = test_df[['review', 'overall']]\n",
    "test_y_df = test_df['sentiment']\n",
    "\n",
    "print(training_x_df.shape, training_y_df.shape)\n",
    "print(test_x_df.shape, test_y_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It appears to be a fatal single car accident until Claire takes a closer look and determines that it might have been a small bomb instead.  Lindsay gets the case, but the FBI quickly take it from her.  Still, she and Richie investigate, but they are finding so few clues.  Will the bomber strike again?Meantime, the FBI has also spotted Mackie Morales, the one who got away.  Cindy becomes obsessed with tracking this psychopath down, with the help of cops, to conduct an interview.  And Yuki is getting married, but her joy might quickly turn to sorrow&#8230;.This series is wildly uneven, but this is definitely one of the better books.  While Claire doesn't wind up with much to do, there are still three storylines that kept me turning pages quickly to find out what would happen next in all of them.  Unfortunately, three plots takes its toll again, and one of them gets short shifted in the climax.  Additionally, the character development is a little shallow.  Still, it was a fun, fast read.Fans of the series will delight to spend time with these ladies.  This is a definite step up from the previous entry.\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "\n",
    "vectorizer.fit(training_x_df['review'])\n",
    "training_x_vectors = vectorizer.transform(training_x_df['review'])\n",
    "\n",
    "print(training_x_df[0, 'review'])\n",
    "print(training_x_vectors[0].toarray()[0][:100])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
