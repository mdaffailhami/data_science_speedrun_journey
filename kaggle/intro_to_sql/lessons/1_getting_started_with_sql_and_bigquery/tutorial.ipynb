{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f13877e0",
   "metadata": {
    "papermill": {
     "duration": 0.00591,
     "end_time": "2023-04-20T18:20:42.530732",
     "exception": false,
     "start_time": "2023-04-20T18:20:42.524822",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Introduction\n",
    "\n",
    "Structured Query Language, or **SQL**, is the programming language used with databases, and it is an important skill for any data scientist. In this course, you'll build your SQL skills using **BigQuery**, a web service that lets you apply SQL to huge datasets.\n",
    "\n",
    "In this lesson, you'll learn the basics of accessing and examining BigQuery datasets. After you have a handle on these basics, we'll come back to build your SQL skills.\n",
    "\n",
    "# Your first BigQuery commands\n",
    "\n",
    "To use BigQuery, we'll import the Python package below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cb674fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-20T18:20:42.546136Z",
     "iopub.status.busy": "2023-04-20T18:20:42.545059Z",
     "iopub.status.idle": "2023-04-20T18:20:42.559750Z",
     "shell.execute_reply": "2023-04-20T18:20:42.557892Z"
    },
    "papermill": {
     "duration": 0.028,
     "end_time": "2023-04-20T18:20:42.563308",
     "exception": false,
     "start_time": "2023-04-20T18:20:42.535308",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.cloud import bigquery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e79a4d9",
   "metadata": {
    "papermill": {
     "duration": 0.004261,
     "end_time": "2023-04-20T18:20:42.572818",
     "exception": false,
     "start_time": "2023-04-20T18:20:42.568557",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The first step in the workflow is to create a [`Client`](https://google-cloud.readthedocs.io/en/latest/bigquery/generated/google.cloud.bigquery.client.Client.html#google.cloud.bigquery.client.Client) object.  As you'll soon see, this `Client` object will play a central role in retrieving information from BigQuery datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc3c2033",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-20T18:20:42.585722Z",
     "iopub.status.busy": "2023-04-20T18:20:42.584943Z",
     "iopub.status.idle": "2023-04-20T18:20:42.594911Z",
     "shell.execute_reply": "2023-04-20T18:20:42.593612Z"
    },
    "papermill": {
     "duration": 0.020293,
     "end_time": "2023-04-20T18:20:42.598281",
     "exception": false,
     "start_time": "2023-04-20T18:20:42.577988",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Kaggle's public dataset BigQuery integration.\n"
     ]
    }
   ],
   "source": [
    "# Create a \"Client\" object\n",
    "client = bigquery.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baca1271",
   "metadata": {
    "papermill": {
     "duration": 0.005046,
     "end_time": "2023-04-20T18:20:42.610036",
     "exception": false,
     "start_time": "2023-04-20T18:20:42.604990",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We'll work with a dataset of posts on [Hacker News](https://news.ycombinator.com/), a website focusing on computer science and cybersecurity news.\n",
    "\n",
    "In BigQuery, each dataset is contained in a corresponding project.  In this case, our `hacker_news` dataset is contained in the `bigquery-public-data` project.  To access the dataset, \n",
    "- We begin by constructing a reference to the dataset with the [`dataset()`](https://google-cloud.readthedocs.io/en/latest/bigquery/generated/google.cloud.bigquery.client.Client.dataset.html#google.cloud.bigquery.client.Client.dataset) method.  \n",
    "- Next, we use the [`get_dataset()`](https://google-cloud.readthedocs.io/en/latest/bigquery/generated/google.cloud.bigquery.client.Client.get_dataset.html#google.cloud.bigquery.client.Client.get_dataset) method, along with the reference we just constructed, to fetch the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcb0e59b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-20T18:20:42.621596Z",
     "iopub.status.busy": "2023-04-20T18:20:42.620699Z",
     "iopub.status.idle": "2023-04-20T18:20:42.986638Z",
     "shell.execute_reply": "2023-04-20T18:20:42.985316Z"
    },
    "papermill": {
     "duration": 0.375679,
     "end_time": "2023-04-20T18:20:42.990258",
     "exception": false,
     "start_time": "2023-04-20T18:20:42.614579",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Construct a reference to the \"hacker_news\" dataset\n",
    "dataset_ref = client.dataset(\"hacker_news\", project=\"bigquery-public-data\")\n",
    "\n",
    "# API request - fetch the dataset\n",
    "dataset = client.get_dataset(dataset_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b995822",
   "metadata": {
    "papermill": {
     "duration": 0.004331,
     "end_time": "2023-04-20T18:20:42.999316",
     "exception": false,
     "start_time": "2023-04-20T18:20:42.994985",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Every dataset is just a collection of tables.  You can think of a dataset as a spreadsheet file containing multiple tables, all composed of rows and columns.\n",
    "\n",
    "We use the `list_tables()` method to list the tables in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7937ccc7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-20T18:20:43.011106Z",
     "iopub.status.busy": "2023-04-20T18:20:43.010402Z",
     "iopub.status.idle": "2023-04-20T18:20:43.295928Z",
     "shell.execute_reply": "2023-04-20T18:20:43.294479Z"
    },
    "papermill": {
     "duration": 0.294642,
     "end_time": "2023-04-20T18:20:43.298793",
     "exception": false,
     "start_time": "2023-04-20T18:20:43.004151",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comments\n",
      "full\n",
      "full_201510\n",
      "stories\n"
     ]
    }
   ],
   "source": [
    "# List all the tables in the \"hacker_news\" dataset\n",
    "tables = list(client.list_tables(dataset))\n",
    "\n",
    "# Print names of all tables in the dataset (there are four!)\n",
    "for table in tables:  \n",
    "    print(table.table_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62261807",
   "metadata": {
    "papermill": {
     "duration": 0.004506,
     "end_time": "2023-04-20T18:20:43.308279",
     "exception": false,
     "start_time": "2023-04-20T18:20:43.303773",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Similar to how we fetched a dataset, we can fetch a table.  In the code cell below, we fetch the `full` table in the `hacker_news` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f1f44ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-20T18:20:43.319972Z",
     "iopub.status.busy": "2023-04-20T18:20:43.319564Z",
     "iopub.status.idle": "2023-04-20T18:20:43.614926Z",
     "shell.execute_reply": "2023-04-20T18:20:43.613465Z"
    },
    "papermill": {
     "duration": 0.304758,
     "end_time": "2023-04-20T18:20:43.617889",
     "exception": false,
     "start_time": "2023-04-20T18:20:43.313131",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Construct a reference to the \"full\" table\n",
    "table_ref = dataset_ref.table(\"full\")\n",
    "\n",
    "# API request - fetch the table\n",
    "table = client.get_table(table_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd85fbd6",
   "metadata": {
    "papermill": {
     "duration": 0.004593,
     "end_time": "2023-04-20T18:20:43.627665",
     "exception": false,
     "start_time": "2023-04-20T18:20:43.623072",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In the next section, you'll explore the contents of this table in more detail.  For now, take the time to use the image below to consolidate what you've learned so far.\n",
    "\n",
    "![first_commands](https://storage.googleapis.com/kaggle-media/learn/images/biYqbUB.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18862828",
   "metadata": {
    "papermill": {
     "duration": 0.004533,
     "end_time": "2023-04-20T18:20:43.637101",
     "exception": false,
     "start_time": "2023-04-20T18:20:43.632568",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Table schema\n",
    "\n",
    "The structure of a table is called its **schema**.  We need to understand a table's schema to effectively pull out the data we want. \n",
    "\n",
    "In this example, we'll investigate the `full` table that we fetched above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "468c6efe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-20T18:20:43.648985Z",
     "iopub.status.busy": "2023-04-20T18:20:43.648544Z",
     "iopub.status.idle": "2023-04-20T18:20:43.657414Z",
     "shell.execute_reply": "2023-04-20T18:20:43.656274Z"
    },
    "papermill": {
     "duration": 0.017504,
     "end_time": "2023-04-20T18:20:43.659628",
     "exception": false,
     "start_time": "2023-04-20T18:20:43.642124",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SchemaField('title', 'STRING', 'NULLABLE', 'Story title', (), None),\n",
       " SchemaField('url', 'STRING', 'NULLABLE', 'Story url', (), None),\n",
       " SchemaField('text', 'STRING', 'NULLABLE', 'Story or comment text', (), None),\n",
       " SchemaField('dead', 'BOOLEAN', 'NULLABLE', 'Is dead?', (), None),\n",
       " SchemaField('by', 'STRING', 'NULLABLE', \"The username of the item's author.\", (), None),\n",
       " SchemaField('score', 'INTEGER', 'NULLABLE', 'Story score', (), None),\n",
       " SchemaField('time', 'INTEGER', 'NULLABLE', 'Unix time', (), None),\n",
       " SchemaField('timestamp', 'TIMESTAMP', 'NULLABLE', 'Timestamp for the unix time', (), None),\n",
       " SchemaField('type', 'STRING', 'NULLABLE', 'Type of details (comment, comment_ranking, poll, story, job, pollopt)', (), None),\n",
       " SchemaField('id', 'INTEGER', 'NULLABLE', \"The item's unique id.\", (), None),\n",
       " SchemaField('parent', 'INTEGER', 'NULLABLE', 'Parent comment ID', (), None),\n",
       " SchemaField('descendants', 'INTEGER', 'NULLABLE', 'Number of story or poll descendants', (), None),\n",
       " SchemaField('ranking', 'INTEGER', 'NULLABLE', 'Comment ranking', (), None),\n",
       " SchemaField('deleted', 'BOOLEAN', 'NULLABLE', 'Is deleted?', (), None)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print information on all the columns in the \"full\" table in the \"hacker_news\" dataset\n",
    "table.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cc84ee",
   "metadata": {
    "papermill": {
     "duration": 0.004625,
     "end_time": "2023-04-20T18:20:43.669738",
     "exception": false,
     "start_time": "2023-04-20T18:20:43.665113",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Each [`SchemaField`](https://googleapis.github.io/google-cloud-python/latest/bigquery/generated/google.cloud.bigquery.schema.SchemaField.html#google.cloud.bigquery.schema.SchemaField) tells us about a specific column (which we also refer to as a **field**). In order, the information is:\n",
    "\n",
    "* The **name** of the column\n",
    "* The **field type** (or datatype) in the column\n",
    "* The **mode** of the column (`'NULLABLE'` means that a column allows NULL values, and is the default)\n",
    "* A **description** of the data in that column\n",
    "\n",
    "The first field has the SchemaField:\n",
    "\n",
    "`SchemaField('by', 'string', 'NULLABLE', \"The username of the item's author.\",())`\n",
    "\n",
    "This tells us:\n",
    "- the field (or column) is called `by`,\n",
    "- the data in this field is strings, \n",
    "- NULL values are allowed, and\n",
    "- it contains the usernames corresponding to each item's author.\n",
    "\n",
    "We can use the [`list_rows()`](https://google-cloud.readthedocs.io/en/latest/bigquery/generated/google.cloud.bigquery.client.Client.list_rows.html#google.cloud.bigquery.client.Client.list_rows) method to check just the first five lines of of the `full` table to make sure this is right. (Sometimes databases have outdated descriptions, so it's good to check.)  This returns a BigQuery [`RowIterator`](https://googleapis.github.io/google-cloud-python/latest/bigquery/generated/google.cloud.bigquery.table.RowIterator.html) object that can quickly be converted to a pandas DataFrame with the [`to_dataframe()`](https://google-cloud.readthedocs.io/en/latest/bigquery/generated/google.cloud.bigquery.table.RowIterator.to_dataframe.html) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a97f5721",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-20T18:20:43.682064Z",
     "iopub.status.busy": "2023-04-20T18:20:43.681194Z",
     "iopub.status.idle": "2023-04-20T18:20:44.246249Z",
     "shell.execute_reply": "2023-04-20T18:20:44.245021Z"
    },
    "papermill": {
     "duration": 0.574327,
     "end_time": "2023-04-20T18:20:44.249056",
     "exception": false,
     "start_time": "2023-04-20T18:20:43.674729",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: Cannot use bqstorage_client if max_results is set, reverting to fetching data with the tabledata.list endpoint.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "      <th>dead</th>\n",
       "      <th>by</th>\n",
       "      <th>score</th>\n",
       "      <th>time</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>type</th>\n",
       "      <th>id</th>\n",
       "      <th>parent</th>\n",
       "      <th>descendants</th>\n",
       "      <th>ranking</th>\n",
       "      <th>deleted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>I would rather just have wired earbuds, period...</td>\n",
       "      <td>None</td>\n",
       "      <td>zeveb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1591717736</td>\n",
       "      <td>2020-06-09 15:48:56+00:00</td>\n",
       "      <td>comment</td>\n",
       "      <td>23467666</td>\n",
       "      <td>23456782</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>DNS?</td>\n",
       "      <td>None</td>\n",
       "      <td>nly</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1572810465</td>\n",
       "      <td>2019-11-03 19:47:45+00:00</td>\n",
       "      <td>comment</td>\n",
       "      <td>21436112</td>\n",
       "      <td>21435130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>These benchmarks seem pretty good.  Filterable...</td>\n",
       "      <td>None</td>\n",
       "      <td>mrkeen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1591717727</td>\n",
       "      <td>2020-06-09 15:48:47+00:00</td>\n",
       "      <td>comment</td>\n",
       "      <td>23467665</td>\n",
       "      <td>23467426</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Oh really?&lt;p&gt;* Excel alone uses 86.1MB of priv...</td>\n",
       "      <td>None</td>\n",
       "      <td>oceanswave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1462987532</td>\n",
       "      <td>2016-05-11 17:25:32+00:00</td>\n",
       "      <td>comment</td>\n",
       "      <td>11677248</td>\n",
       "      <td>11676886</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>These systems are useless.  Of the many flaws:...</td>\n",
       "      <td>None</td>\n",
       "      <td>nyxxie</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1572810473</td>\n",
       "      <td>2019-11-03 19:47:53+00:00</td>\n",
       "      <td>comment</td>\n",
       "      <td>21436113</td>\n",
       "      <td>21435025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  title   url                                               text  dead  \\\n",
       "0  None  None  I would rather just have wired earbuds, period...  None   \n",
       "1  None  None                                               DNS?  None   \n",
       "2  None  None  These benchmarks seem pretty good.  Filterable...  None   \n",
       "3  None  None  Oh really?<p>* Excel alone uses 86.1MB of priv...  None   \n",
       "4  None  None  These systems are useless.  Of the many flaws:...  None   \n",
       "\n",
       "           by  score        time                 timestamp     type        id  \\\n",
       "0       zeveb    NaN  1591717736 2020-06-09 15:48:56+00:00  comment  23467666   \n",
       "1         nly    NaN  1572810465 2019-11-03 19:47:45+00:00  comment  21436112   \n",
       "2      mrkeen    NaN  1591717727 2020-06-09 15:48:47+00:00  comment  23467665   \n",
       "3  oceanswave    NaN  1462987532 2016-05-11 17:25:32+00:00  comment  11677248   \n",
       "4      nyxxie    NaN  1572810473 2019-11-03 19:47:53+00:00  comment  21436113   \n",
       "\n",
       "     parent  descendants  ranking deleted  \n",
       "0  23456782          NaN      NaN    None  \n",
       "1  21435130          NaN      NaN    None  \n",
       "2  23467426          NaN      NaN    None  \n",
       "3  11676886          NaN      NaN    None  \n",
       "4  21435025          NaN      NaN    None  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview the first five lines of the \"full\" table\n",
    "client.list_rows(table, max_results=5).to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205aaf15",
   "metadata": {
    "papermill": {
     "duration": 0.005052,
     "end_time": "2023-04-20T18:20:44.259626",
     "exception": false,
     "start_time": "2023-04-20T18:20:44.254574",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The `list_rows()` method will also let us look at just the information in a specific column. If we want to see the first five entries in the `by` column, for example, we can do that!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "779b1f0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-20T18:20:44.273217Z",
     "iopub.status.busy": "2023-04-20T18:20:44.272095Z",
     "iopub.status.idle": "2023-04-20T18:20:44.654541Z",
     "shell.execute_reply": "2023-04-20T18:20:44.653267Z"
    },
    "papermill": {
     "duration": 0.391759,
     "end_time": "2023-04-20T18:20:44.657150",
     "exception": false,
     "start_time": "2023-04-20T18:20:44.265391",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: Cannot use bqstorage_client if max_results is set, reverting to fetching data with the tabledata.list endpoint.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  title\n",
       "0  None\n",
       "1  None\n",
       "2  None\n",
       "3  None\n",
       "4  None"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview the first five entries in the \"by\" column of the \"full\" table\n",
    "client.list_rows(table, selected_fields=table.schema[:1], max_results=5).to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc433d8d",
   "metadata": {
    "papermill": {
     "duration": 0.005294,
     "end_time": "2023-04-20T18:20:44.668090",
     "exception": false,
     "start_time": "2023-04-20T18:20:44.662796",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Disclaimer\n",
    "Before we go into the coding exercise, a quick disclaimer for those who already know some SQL:\n",
    "\n",
    "**Each Kaggle user can scan 5TB every 30 days for free.  Once you hit that limit, you'll have to wait for it to reset.**\n",
    "\n",
    "The commands you've seen so far won't demand a meaningful fraction of that limit. But some BiqQuery datasets are huge. So, if you already know SQL, wait to run SELECT queries until you've seen how to use your allotment effectively. If you are like most people reading this, you don't know how to write these queries yet, so you don't need to worry about this disclaimer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eac0f81",
   "metadata": {
    "papermill": {
     "duration": 0.005314,
     "end_time": "2023-04-20T18:20:44.679050",
     "exception": false,
     "start_time": "2023-04-20T18:20:44.673736",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Your turn\n",
    "Practice the commands you've seen to **[explore the structure of a dataset](https://www.kaggle.com/kernels/fork/1058477)** with crimes in the city of Chicago."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4e9c98",
   "metadata": {
    "papermill": {
     "duration": 0.005358,
     "end_time": "2023-04-20T18:20:44.690120",
     "exception": false,
     "start_time": "2023-04-20T18:20:44.684762",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "*Have questions or comments? Visit the [course discussion forum](https://www.kaggle.com/learn/intro-to-sql/discussion) to chat with other learners.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 13.46499,
   "end_time": "2023-04-20T18:20:45.318934",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-04-20T18:20:31.853944",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
